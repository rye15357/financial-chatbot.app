import streamlit as st
import os
from dotenv import load_dotenv
from huggingface_hub import login
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain_core.prompts import PromptTemplate
from langchain_huggingface import HuggingFaceEmbeddings, HuggingFacePipeline
from datetime import datetime
import openai
import torch
import re
import subprocess
import requests
import pandas as pd
import time 
import hashlib
from lang_pack import LANG_PACK
import json
import matplotlib.pyplot as plt
import shutil

plt.rcParams['font.sans-serif'] = [
    'Microsoft JhengHei',           # Windows
    'Noto Sans CJK TC',             # Linux/Google Cloud, å¾ˆå¸¸è¦‹
    'AR PL UMing TW',               # Ubuntu ä¹Ÿæœ‰
    'sans-serif'                    # å…¶ä»–é è¨­
]
plt.rcParams['axes.unicode_minus'] = False

# === .env & Token åˆå§‹åŒ– ===
load_dotenv()
token = os.getenv("HUGGINGFACEHUB_API_TOKEN")
serper_api_key = os.getenv("SERPER_API_KEY")
openai_api_key = os.getenv("OPENAI_API_KEY")

def login_hf(token):
    try:
        login(token=token)
    except Exception as e:
        st.error(f"Hugging Face Token ç™»å…¥å¤±æ•—ï¼š{e}")
        st.stop()

if not token:
    st.error("è«‹è¨­å®š HUGGINGFACEHUB_API_TOKEN")
    st.stop()
if not openai_api_key:
    st.error("è«‹è¨­å®š OPENAI_API_KEY")
    st.stop()

# åªåœ¨ Session ç¬¬ä¸€æ¬¡ login
if "hf_logged_in" not in st.session_state:
    login_hf(token)
    st.session_state["hf_logged_in"] = True

openai.api_key = openai_api_key

# è·¯å¾‘åˆå§‹åŒ–
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
VECTOR_DIR = os.path.join(BASE_DIR, "vectorstore")
os.makedirs(VECTOR_DIR, exist_ok=True)
DATA_DIR = os.path.join(BASE_DIR, "data")
os.makedirs(DATA_DIR, exist_ok=True)

MAPPING_PATH = os.path.join(BASE_DIR, "company_mapping.json")

def load_company_mapping():
    if os.path.exists(MAPPING_PATH):
        with open(MAPPING_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}

def save_company_mapping(mapping):
    with open(MAPPING_PATH, "w", encoding="utf-8") as f:
        json.dump(mapping, f, ensure_ascii=False, indent=2)

company_mapping = load_company_mapping()  # { safe_folder: ä¸­æ–‡å }

# ==== èŠå¤©ç´€éŒ„ç›¸é—œ ====

def ask_openai(prompt, model="gpt-4o", temperature=0.7, lang="ç¹é«”ä¸­æ–‡", history=None):
    # å¼·åŒ– AI åˆ†æå¸«é¢¨æ ¼
    if lang == "ç¹é«”ä¸­æ–‡":
        system_prompt = (
            "ä½ æ˜¯ä¸€ä½é ‚å°–çš„è²¡ç¶“ç”¢æ¥­åˆ†æå¸«ï¼Œå°ˆç²¾å°ç£/å…¨çƒä¸Šå¸‚æ«ƒå…¬å¸ã€åŠå°é«”èˆ‡AIç”¢æ¥­ã€‚"
            "é‡å°ç”¨æˆ¶å•é¡Œï¼Œè«‹ç”¨ä»¥ä¸‹çµæ§‹å›ç­”ï¼š\n"
            "1. æ¢åˆ—ã€é—œéµæ•¸æ“šã€‘æˆ–ã€ç”¢æ¥­é‡é»ã€‘\n"
            "2. æ¢åˆ—ã€å½±éŸ¿å› ç´ ã€‘æˆ–ã€è¶¨å‹¢/æŒ‘æˆ°ã€‘\n"
            "3. æœ€å¾Œçµ¦ä¸€æ®µã€å°ˆæ¥­è§€é»/æŠ•è³‡å»ºè­°ã€‘ï¼Œå‹™å¿…æ˜ç¢ºã€æœ‰æ·±åº¦ã€‚\n"
            "å¦‚æœè³‡æ–™ä¸è¶³ï¼Œè«‹æ˜èªªã€è³‡è¨Šæœ‰é™ã€ï¼Œä¸¦æ ¹æ“šç”¢æ¥­è¶¨å‹¢åˆç†æ¨ä¼°ã€‚"
            "å›è¦†å‹™å¿…åš´è¬¹ã€å°ˆæ¥­ï¼Œä¸è¦æœæ’°ä¾†æºï¼Œä¸è¦ç”¨å¤ªå£èªçš„èªæ°£ã€‚"
        )
    else:
        system_prompt = (
            "You are a top financial and industry analyst, specializing in global and Taiwanese listed companies, semiconductors, and AI. "
            "For any question, structure your answer as follows:\n"
            "1. List [Key Figures] or [Industry Highlights]\n"
            "2. List [Factors/Trends/Challenges]\n"
            "3. Conclude with a clear [Analyst View/Investment Suggestion].\n"
            "If data is limited, explicitly say so, and provide reasoned industry-based estimates. "
            "Your tone should be precise and professional, avoid making up data, and do not be overly casual."
        )
    messages = [{"role": "system", "content": system_prompt}]
    if history:
        messages.extend(history)
    messages.append({"role": "user", "content": prompt})
    client = openai.OpenAI(api_key=openai.api_key)
    completion = client.chat.completions.create(
        model=model,
        messages=messages,
        temperature=temperature,
        max_tokens=1000
    )
    return completion.choices[0].message.content.strip()


def get_cached_summary_path(company):
    return os.path.join(VECTOR_DIR, company, "summary.txt")

def save_summary_to_cache(company, summary):
    summary_path = get_cached_summary_path(company)
    with open(summary_path, "w", encoding="utf-8") as f:
        f.write(summary)

def load_summary_from_cache(company):
    summary_path = get_cached_summary_path(company)
    if os.path.exists(summary_path):
        with open(summary_path, "r", encoding="utf-8") as f:
            return f.read()
    return None

def get_chat_path(user_id, topic):
    user_dir = f"chats/{user_id}"
    os.makedirs(user_dir, exist_ok=True)
    return f"{user_dir}/{topic}.json"

def save_chat(messages, user_id, topic):
    path = get_chat_path(user_id, topic)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(messages, f, ensure_ascii=False, indent=2)

def load_chat(user_id, topic):
    path = get_chat_path(user_id, topic)
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

def list_topics(user_id):
    user_dir = f"chats/{user_id}"
    if not os.path.exists(user_dir):
        return []
    return [f[:-5] for f in os.listdir(user_dir) if f.endswith('.json')]

def list_users():
    if not os.path.exists("chats"):
        return []
    return [d for d in os.listdir("chats") if os.path.isdir(os.path.join("chats", d))]

# ==== LLM QA & åˆ†æ ====
qa_prompt_template_zh = """
ä½ æ˜¯ä¸€ä½å°ˆæ¥­è²¡å ± AI åŠ©ç†ã€‚è«‹æ ¹æ“šä¸‹åˆ—è²¡å ±å…§å®¹ï¼Œé‡å°å•é¡Œç”¨ã€Œä¸€å¥è‡ªç„¶ã€æ¸…æ¥šã€ç°¡çŸ­ã€çš„ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¸è¦è¤‡è£½åŸæ–‡ï¼Œä¸éœ€è¦ä¾†æºèˆ‡é ç¢¼ã€‚

ğŸ“Š è²¡å ±å…§å®¹ï¼ˆåƒè€ƒï¼‰ï¼š
{context}

ğŸ” å•é¡Œï¼š
{question}

è«‹ç›´æ¥èªªæ˜é—œéµæ•¸å­—æˆ–çµè«–ã€‚å¦‚æœè²¡å ±ä¸­æ‰¾ä¸åˆ°æ˜ç¢ºç­”æ¡ˆï¼Œè«‹å›è¦†ã€ŒæŸ¥ç„¡æ˜ç¢ºè³‡æ–™ã€ã€‚
"""
qa_prompt_template_en = """
You are a professional financial report AI assistant. Based on the following report content, answer the question with a concise and natural English sentence. Do not copy original text or cite pages.

ğŸ“Š Financial Content (for reference only):
{context}

ğŸ” Question:
{question}

Directly state the key figure or conclusion. If no clear answer, reply: "No clear information found."
"""
analysis_prompt_template_zh = """
ä½ æ˜¯ä¸€ä½è²¡ç¶“é¡§å•ï¼Œæ ¹æ“šä¸‹åˆ—å…§å®¹é€²è¡Œæƒ…ç·’èˆ‡å‰æ™¯åˆ†æã€‚è«‹ç”¨ä¸€å¥è©±ç¸½çµï¼Œä¸¦æ¨™ç¤ºï¼ˆæ¨‚è§€ï¼ä¸­æ€§ï¼ä¿å®ˆï¼‰ã€‚

ğŸ“œ è²¡å‹™èªªæ˜ï¼š
{text}
"""
analysis_prompt_template_en = """
You are a financial consultant. Analyze the sentiment and outlook of the following financial statement. Use one sentence and indicate (Optimistic/Neutral/Conservative).

ğŸ“œ Financial Description:
{text}
"""

@st.cache_resource
def load_llm():
    try:
        model_id = "Qwen/Qwen1.5-1.8B-Chat"
        tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)
        model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True).to("cuda" if torch.cuda.is_available() else "cpu")
        pipe = pipeline(
            "text-generation",
            model=model,
            tokenizer=tokenizer,
            max_new_tokens=512,
            do_sample=True,
            temperature=0.7,
            top_k=50,
            top_p=0.95,
            repetition_penalty=1.1,
            pad_token_id=tokenizer.eos_token_id or tokenizer.pad_token_id or tokenizer.unk_token_id,
            device=0 if torch.cuda.is_available() else -1
        )
        return HuggingFacePipeline(pipeline=pipe)
    except Exception as e:
        st.error(f"æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return None

@st.cache_resource
def get_qa_bot(DB_FAISS_PATH, lang):
    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2', model_kwargs={'device': 'cpu'})
    try:
        db = FAISS.load_local(DB_FAISS_PATH, embeddings, allow_dangerous_deserialization=True)
    except Exception as e:
        st.error(f"å‘é‡è³‡æ–™åº«è¼‰å…¥å¤±æ•—: {e}")
        return None
    llm = load_llm()
    if not llm:
        return None
    if lang == "ç¹é«”ä¸­æ–‡":
        prompt = PromptTemplate(template=qa_prompt_template_zh, input_variables=['context', 'question'])
    else:
        prompt = PromptTemplate(template=qa_prompt_template_en, input_variables=['context', 'question'])
    retriever = db.as_retriever(search_type="mmr", search_kwargs={"k": 2})
    return RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        chain_type_kwargs={"prompt": prompt}
    )

@st.cache_resource
def get_analysis_pipeline(lang):
    llm = load_llm()
    if lang == "ç¹é«”ä¸­æ–‡":
        analysis_prompt = PromptTemplate(template=analysis_prompt_template_zh, input_variables=['text'])
    else:
        analysis_prompt = PromptTemplate(template=analysis_prompt_template_en, input_variables=['text'])
    return (analysis_prompt | llm)


def extract_twd_amount(text, query=""):
    keywords = ["ç‡Ÿæ¥­æ”¶å…¥", "æ”¶å…¥", "revenue", "sales", "income", "total"]
    try:
        if any(k in query.lower() for k in keywords) or any(k in text for k in keywords):
            match = re.search(r"(ç‡Ÿæ¥­æ”¶å…¥|æ”¶å…¥|revenue|sales|income)[^0-9]{0,10}([0-9,\.]+)\s*(å„„|å„„å…ƒ|ä»Ÿå…ƒ|åƒå…ƒ|ç™¾è¬å…ƒ|è¬å…ƒ|å…ƒ|million|billion)?", text, re.IGNORECASE)
            if match:
                num = match.group(2)
                unit = match.group(3) or ""
                return f"{num}{unit}"
        all_matches = re.findall(r"([0-9,\.]+)\s*(å„„|å„„å…ƒ|ä»Ÿå…ƒ|åƒå…ƒ|ç™¾è¬å…ƒ|è¬å…ƒ|å…ƒ)", text)
        if all_matches:
            biggest = max(all_matches, key=lambda x: float(x[0].replace(',', '')))
            return f"{biggest[0]}{biggest[1]}"
    except Exception:
        pass
    return None

def extract_eps_amount(text, query=""):
    # æ”¯æ´EPSå•æ³•
    if "eps" in query.lower() or "æ¯è‚¡ç›ˆé¤˜" in query or "EPS" in text:
        match = re.search(r"(EPS|æ¯è‚¡ç›ˆé¤˜)[^\d\-\.]{0,10}([\-]?[0-9]+(?:\.[0-9]+)?)", text, re.IGNORECASE)
        if match:
            return match.group(2)
    return None

def extract_net_income(text, query=""):
    if "æ·¨åˆ©" in query or "net income" in query.lower() or "æ·¨åˆ©" in text:
        match = re.search(r"(æ·¨åˆ©|net income)[^0-9\-]{0,10}([\-]?[0-9,\.]+)\s*(å„„|ç™¾è¬|è¬å…ƒ|å…ƒ)?", text, re.IGNORECASE)
        if match:
            return f"{match.group(2)}{match.group(3) or ''}"
    return None

def extract_gross_margin(text, query=""):
    if "æ¯›åˆ©ç‡" in query or "gross margin" in query.lower() or "æ¯›åˆ©ç‡" in text:
        match = re.search(r"(æ¯›åˆ©ç‡|gross margin)[^\d\-\.]{0,10}([\-]?[0-9\.]+)\s*%", text, re.IGNORECASE)
        if match:
            return f"{match.group(2)}%"
    return None

def extract_amount_by_type(text, query=""):
    # å°‹æ‰¾æ‰€æœ‰æœ‰å–®ä½çš„æ•¸å­—ï¼Œé¿å…å¹´ä»½
    matches = re.findall(r"([0-9,\.]+)\s*(å„„|å„„å…ƒ|ä»Ÿå…ƒ|åƒå…ƒ|ç™¾è¬|ç™¾è¬å…ƒ|è¬å…ƒ|å…ƒ|million|billion|%)", text)
    results = []
    for num, unit in matches:
        try:
            val = float(num.replace(",", ""))
            # å¹´ä»½ç¯„åœé€šå¸¸ä¸æœƒæœ‰å–®ä½ï¼Œä½†é‚„æ˜¯ä¿å®ˆæ’é™¤1900~2100
            if 1900 <= val <= 2100:
                continue
            results.append(f"{num}{unit}")
        except:
            continue
    # å¦‚æœæœ‰å¤šå€‹ï¼Œé€šå¸¸ç¬¬ä¸€å€‹å°±æ˜¯
    if results:
        return results[0]
    # å¦‚æœæ²’æ‰¾åˆ°æœ‰å–®ä½çš„æ•¸å­—ï¼Œå¯ä»¥ä¿ç•™ä½ åŸæœ¬çš„è¬ç”¨æ¢ä»¶
    return None


def safe_folder_name(name):
    ascii_name = re.sub(r"[^\w]", "_", name)
    ascii_name = re.sub(r"[^a-zA-Z0-9_]", "_", ascii_name)
    hash_part = hashlib.md5(name.encode("utf-8")).hexdigest()[:8]
    return f"{ascii_name.lower()}_{hash_part}"


def get_company_year_data(companies, indicator, years):
    """
    æŸ¥è©¢å¤šå®¶å…¬å¸å¤šå¹´åº¦å–®ä¸€æŒ‡æ¨™ï¼ˆå¦‚ç‡Ÿæ”¶/EPSï¼‰è³‡æ–™ä¾†æºï¼šWeb > OpenAI > PDF
    åƒæ•¸ï¼š
        companies: ["å°ç©é›»", "é´»æµ·"]
        indicator: "ç‡Ÿæ”¶" æˆ– "Revenue"
        years: [2021,2022,2023]
    å›å‚³ï¼šDataFrame æ¬„ä½ ["å…¬å¸", "å¹´åº¦", indicator, "ä¾†æº"]
    """
    rows = []
    search_map = {
        "ç‡Ÿæ”¶": "ç‡Ÿæ”¶", "Revenue": "ç‡Ÿæ”¶",
        "æ·¨åˆ©": "æ·¨åˆ©", "Net Income": "æ·¨åˆ©",
        "EPS": "EPS",
        "æ¯›åˆ©ç‡": "æ¯›åˆ©ç‡", "Gross Margin": "æ¯›åˆ©ç‡"
    }
    for company in companies:
        for year in years:
            # 1. æŸ¥ Web
            query = f"{company} {year}å¹´ {search_map[indicator]}"
            web_result = web_search(query)
            match = re.search(r'([0-9,\.]+)\s*(å„„|ä»Ÿå…ƒ|åƒå…ƒ|ç™¾è¬|è¬å…ƒ|å…ƒ|%)', web_result)
            if match:
                value, unit = match.groups()
                val = float(value.replace(",", ""))
                if "%" in unit:
                    pass
                else:
                    multiplier = {
                        "å„„": 1e8, "ä»Ÿå…ƒ": 1e3, "åƒå…ƒ": 1e3,
                        "ç™¾è¬": 1e6, "è¬å…ƒ": 1e4, "å…ƒ": 1
                    }.get(unit, 1)
                    val = val * multiplier
                rows.append({"å…¬å¸": company, "å¹´åº¦": year, indicator: val, "ä¾†æº": "ç¶²è·¯"})
                continue

            # 2. æŸ¥ GPT-4o
            prompt = f"è«‹åˆ—å‡º{company} {year}å¹´{indicator}ï¼ˆå–®ä½ï¼šå„„å…ƒæˆ–%ï¼‰ï¼Œåªçµ¦æ•¸å­—ï¼Œä¸è¦èªªæ˜ï¼Œå›å‚³æ ¼å¼ï¼š{year},{indicator}=?"
            gpt_result = ask_openai(prompt, model="gpt-4o")
            match2 = re.search(r'([0-9,\.]+)\s*(å„„|ä»Ÿå…ƒ|åƒå…ƒ|ç™¾è¬|è¬å…ƒ|å…ƒ|%)', gpt_result)
            if match2:
                value, unit = match2.groups()
                val = float(value.replace(",", ""))
                if "%" in unit:
                    pass
                else:
                    multiplier = {
                        "å„„": 1e8, "ä»Ÿå…ƒ": 1e3, "åƒå…ƒ": 1e3,
                        "ç™¾è¬": 1e6, "è¬å…ƒ": 1e4, "å…ƒ": 1
                    }.get(unit, 1)
                    val = val * multiplier
                rows.append({"å…¬å¸": company, "å¹´åº¦": year, indicator: val, "ä¾†æº": "GPT-4o"})
                continue

            # 3. æŸ¥ PDFï¼ˆæœ¬åœ°ï¼‰
            safe_names = [k for k, v in company_mapping.items() if v == company]
            if safe_names:
                safe_name = safe_names[0]
                DB_FAISS_PATH = os.path.join(VECTOR_DIR, safe_name, "db_faiss")
                if os.path.exists(DB_FAISS_PATH):
                    qa = get_qa_bot(DB_FAISS_PATH, "ç¹é«”ä¸­æ–‡")
                    if qa:
                        pdf_result = qa.invoke({"query": f"{year}å¹´{indicator}å¤šå°‘"})
                        pdf_val = extract_amount_by_type(str(pdf_result), f"{year}å¹´{indicator}")
                        if pdf_val:
                            try:
                                val = float(re.sub(r"[^\d\.]", "", pdf_val))
                                rows.append({"å…¬å¸": company, "å¹´åº¦": year, indicator: val, "ä¾†æº": "PDF"})
                            except:
                                pass
    df = pd.DataFrame(rows)
    return df

def web_search(query, retry=2):
    url = "https://google.serper.dev/search"
    payload = {"q": query}
    headers = {
        "X-API-KEY": serper_api_key,
        "Content-Type": "application/json"
    }
    for i in range(retry+1):
        try:
            resp = requests.post(url, json=payload, headers=headers, timeout=8)
            data = resp.json()
            results = []
            all_snippets = ""
            for r in data.get("organic", [])[:3]:
                title = r.get("title")
                link = r.get("link")
                snippet = r.get("snippet", "")
                results.append(f"ã€{title}ã€‘\n{snippet}\n{link}")
                all_snippets += snippet + " "
            match = re.search(r'([0-9,\.]+)\s*(å„„|å„„å…ƒ|ä»Ÿå…ƒ|åƒè¬å…ƒ|ç™¾è¬å…ƒ|è¬å…ƒ|å…ƒ)', all_snippets)
            if match:
                amount = match.group(0)
                return f"\U0001f310 ä¾†æºï¼šç¶²è·¯\n\U0001f4b0 é‡‘é¡æ“·å–ï¼š**{amount}**\n\n" + "\n\n".join(results)
            return "\U0001f310 ä¾†æºï¼šç¶²è·¯\n" + "\n\n".join(results) if results else "âŒ ç„¡æ³•å¾ç¶²è·¯æŸ¥å¾—è³‡æ–™"
        except Exception as e:
            if i < retry:
                continue
            return f"âŒ ç¶²è·¯æŸ¥è©¢éŒ¯èª¤ï¼š{e}"

def parse_web_search_result(news_result, query=""):
    amount = extract_amount_by_type(news_result, query)
    news_list = []
    source_snippets = []
    news_pattern = r"ã€(.+?)ã€‘\n(.+?)\n(https?://[^\s]+)"
    for m in re.finditer(news_pattern, news_result):
        news_list.append({
            "title": m.group(1),
            "desc": m.group(2),
            "link": m.group(3)
        })
        source_snippets.append(m.group(2))
    return amount or "ï¼ˆæŸ¥ç„¡ï¼‰", news_list, source_snippets


def build_ai_reply(company, user_input, answer, amount, growth, news_list, source_snippets, T):
    bullets = []
    if answer:
        bullets.append(f"{company} {T['revenue']} {amount}, {T['yoy_growth']} {growth}.")
        bullets.append(T["ai_bullet1"])
        bullets.append(T["ai_bullet2"])
    else:
        bullets.append(T["no_data"])
    news_md = "\n".join([f"- [{n['title']}]({n['link']})ï¼š{n['desc']}" for n in news_list]) if news_list else T["no_news"]
    sources_md = "\n".join([f"> {s}" for s in source_snippets]) if source_snippets else ""
    reply = f"""

{T['ai_reply_title']}

---
{T['key_data_card']}
- **{T['company']}**ï¼š{company}
- **{T['query']}**ï¼š{user_input}
- **{T['revenue']}**ï¼š<span style="color:orange;font-weight:bold;">{amount}</span>
- **{T['yoy_growth']}**ï¼š{growth}

---

{T['ai_bullets']}
{chr(10).join([f"{i+1}. {b}" for i, b in enumerate(bullets)])}

---

{T['news_sources']}
{news_md}

---

{sources_md}
{T['also_ask']}

---
{T['ai_footer']}
"""
    return reply


# ==== å…¬å¸/å‘é‡/èªè¨€ ====
def get_companies_list():
    if not os.path.exists(VECTOR_DIR):
        return []
    return [d for d in os.listdir(VECTOR_DIR) if os.path.isdir(os.path.join(VECTOR_DIR, d))]

# ==== Streamlit ä»‹é¢ ====
st.set_page_config(page_title="è²¡å ±åŠ©ç†AI", page_icon=":robot_face:", layout="wide")
multi_lang = st.sidebar.selectbox(
    LANG_PACK["ç¹é«”ä¸­æ–‡"]["language_select"],
    list(LANG_PACK.keys()),
    key="lang_select"
)
if "lang_last" not in st.session_state or st.session_state["lang_last"] != multi_lang:
    st.session_state["lang_last"] = multi_lang
    st.rerun()
T = LANG_PACK[multi_lang]

# --- Sidebar: ç”¨æˆ¶/ä¸»é¡Œ ---
st.sidebar.markdown("## âš™ï¸ " + T["model_setting"])
model_options = ["Qwen1.8", "OpenAI GPT-4o"]
selected_model = st.sidebar.selectbox(T["model_select"], model_options, key="model_select")

st.sidebar.header(T["user_and_topic"])
users = list_users()
if not users:
    user_id = st.sidebar.text_input(T["user_input"], value="guest", key="user_id_new")
    if st.sidebar.button(T["add_user"]):
        if user_id:
            os.makedirs(f"chats/{user_id}", exist_ok=True)
            st.success(f"{T['add_user']}ï¼š{user_id}")
            st.rerun()
else:
    user_options = users + [T["add_user"]]
    user_id = st.sidebar.selectbox("ğŸ‘¤ " + T["user_label"], user_options, index=0, key="user_select")

    if user_id == T["add_user"]:
        new_user = st.sidebar.text_input(T["user_input"], key="new_user_id")
        if st.sidebar.button("âœ… " + T["add_user_btn"], key="add_user_btn"):
            if new_user and new_user not in users:
                os.makedirs(f"chats/{new_user}", exist_ok=True)
                st.success(f"âœ… {T['add_user']}ï¼š{new_user}")
                st.rerun()
            else:
                st.warning(T["user_input"])
    else:
        st.session_state["user_id"] = user_id

# ==== ğŸ“ ä¸»é¡Œé¸æ“‡ ====
all_add_topic_names = [v["add_topic"] for v in LANG_PACK.values()] + ["+ æ–°å¢ä¸»é¡Œ", "+ Add Topic"]
topics = list_topics(user_id)
topic_options = [t for t in topics if t not in all_add_topic_names]
topic_options.append(T["add_topic"])
topic = st.sidebar.selectbox(
    "ğŸ“ " + T["topic_label"],
    topic_options,
    index=0,
    key=f"topic_select_{user_id}"
)


if topic == T["add_topic"]:
    topic_new = st.sidebar.text_input(T["topic_input"], key="new_topic_name")
    if st.sidebar.button("âœ… " + T["confirm_add_topic"], key="add_topic_btn"):
        path = f"chats/{user_id}/{topic_new}.json"
        if not os.path.exists(path):
            with open(path, "w", encoding="utf-8") as f:
                json.dump([], f)
            st.success(f"âœ… å·²æ–°å¢ä¸»é¡Œï¼š{topic_new}")
            st.rerun()
        else:
            st.warning("âš ï¸ ä¸»é¡Œå·²å­˜åœ¨" if multi_lang == "ç¹é«”ä¸­æ–‡" else "âš ï¸ Topic already exists")
else:
    st.session_state["topic"] = topic

# åˆªé™¤ç”¨æˆ¶ï¼ˆå…©éšæ®µç¢ºèªï¼‰
delete_user_key = f"delete_user_confirm_{user_id}"
if user_id and user_id != T["add_user"]:
    if st.sidebar.button(f"{T['delete_user']} [{user_id}]", key=f"delete_user_btn_{user_id}"):
        st.session_state[delete_user_key] = True
    if st.session_state.get(delete_user_key, False):
        st.sidebar.warning("âš ï¸ æ­¤æ“ä½œä¸å¯å¾©åŸï¼Œè«‹å†æ¬¡é»æ“Šä¸‹æ–¹æŒ‰éˆ•ç¢ºèªï¼" if multi_lang=="ç¹é«”ä¸­æ–‡" else "âš ï¸ This cannot be undone, click again to confirm!")
        if st.sidebar.button("âš¡ï¸ ç¢ºèªæ°¸ä¹…åˆªé™¤" if multi_lang=="ç¹é«”ä¸­æ–‡" else "âš¡ï¸ Confirm Permanent Delete", key=f"delete_user_really_{user_id}"):
            user_dir = os.path.join("chats", user_id)
            try:
                shutil.rmtree(user_dir)
                st.success(f"{T['delete_user']}ï¼š{user_id}")
                st.session_state[delete_user_key] = False
                st.rerun()
            except Exception as e:
                st.error(f"åˆªé™¤ç”¨æˆ¶å¤±æ•—ï¼š{e}" if multi_lang=="ç¹é«”ä¸­æ–‡" else f"Delete user failed: {e}")


else:
    if st.sidebar.button("åˆ‡æ›ä¸»é¡Œ" if multi_lang=="ç¹é«”ä¸­æ–‡" else "Switch Topic"):
        st.session_state["messages"] = load_chat(user_id, topic)
        st.success(f"åˆ‡æ›åˆ°ç”¨æˆ¶ [{user_id}] ä¸»é¡Œ [{topic}]" if multi_lang=="ç¹é«”ä¸­æ–‡" else f"Switched to user [{user_id}], topic [{topic}]")
    if "messages" not in st.session_state:
        st.session_state["messages"] = load_chat(user_id, topic)

# åˆªé™¤ä¸»é¡Œï¼ˆå…©éšæ®µï¼‰

delete_topic_key = f"delete_topic_confirm_{topic}"
if topic != T["add_topic"]:  # âœ… æ’é™¤æ–°å¢ä¸»é¡Œé¸é …
    if st.sidebar.button(f"{T['delete_topic']} [{topic}]", key=f"delete_topic_btn_{topic}"):
        st.session_state[delete_topic_key] = True
    if st.session_state.get(delete_topic_key, False):
        st.sidebar.warning("âš ï¸ æ­¤æ“ä½œä¸å¯å¾©åŸï¼Œè«‹å†æ¬¡é»æ“Šä¸‹æ–¹æŒ‰éˆ•ç¢ºèªï¼" if multi_lang=="ç¹é«”ä¸­æ–‡" else "âš ï¸ This cannot be undone, click again to confirm!")
        if st.sidebar.button("âš¡ï¸ ç¢ºèªæ°¸ä¹…åˆªé™¤" if multi_lang=="ç¹é«”ä¸­æ–‡" else "âš¡ï¸ Confirm Permanent Delete", key=f"delete_topic_really_{topic}"):
            chat_file = get_chat_path(user_id, topic)
            try:
                if os.path.exists(chat_file):
                    os.remove(chat_file)
                    st.success(f"{T['delete_topic']}ï¼š{topic}")
                    st.session_state[delete_topic_key] = False
                    st.rerun()
                else:
                    st.warning("ä¸»é¡Œæª”æ¡ˆä¸å­˜åœ¨" if multi_lang=="ç¹é«”ä¸­æ–‡" else "Topic file not found")
            except Exception as e:
                st.error(f"åˆªé™¤ä¸»é¡Œå¤±æ•—ï¼š{e}" if multi_lang=="ç¹é«”ä¸­æ–‡" else f"Delete topic failed: {e}")


# Sidebar: å…¬å¸+PDF
# æ”¾åœ¨æ‰€æœ‰ sidebar è¼¸å…¥å…ƒä»¶ä¹‹å‰
if st.session_state.get("after_build_db"):
    st.session_state["sidebar_company_input"] = ""
    st.session_state["sidebar_pdf_uploader"] = None
    st.session_state["after_build_db"] = False

# ==== å…¬å¸PDFä¸Šå‚³ ====
st.sidebar.header(T["upload_pdf"])
company_name = st.sidebar.text_input(T["company_name"], value="", key="sidebar_company_input")
if not company_name.strip():
    st.sidebar.warning(T["pdf_upload_tip"])
    uploaded_file = None
else:
    uploaded_file = st.sidebar.file_uploader(T["upload_pdf"], type="pdf", key="sidebar_pdf_uploader")
    if uploaded_file is not None:
        now = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_name = safe_folder_name(company_name)
        pdf_filename = f"{safe_name}_{now}.pdf"
        pdf_path = os.path.join("data", pdf_filename)
        os.makedirs(os.path.dirname(pdf_path), exist_ok=True)
        with open(pdf_path, "wb") as f:
            f.write(uploaded_file.read())
        with st.spinner("å»ºæ§‹å‘é‡è³‡æ–™åº«ä¸­...ï¼ˆè«‹å‹¿é‡æ–°æ•´ç†æˆ–æ“ä½œï¼Œé è¨ˆ 10-30 ç§’ï¼‰" if multi_lang=="ç¹é«”ä¸­æ–‡" else "Building vector DB... Please wait."):
            try:
                result = subprocess.run(
                    ["python", "create_db.py", "--pdf", pdf_path, "--company", company_name],
                    capture_output=True,
                    text=True,
                    check=False
                )
                if result.returncode == 0:
                    company_mapping[safe_name] = company_name
                    save_company_mapping(company_mapping)
                    waited = 0
                    while waited < 5:
                        new_map = load_company_mapping()
                        new_list = get_companies_list()
                        if safe_name in new_map and safe_name in new_list:
                            break
                        time.sleep(0.1)
                        waited += 0.1
                    if not (safe_name in new_map and safe_name in new_list):
                        st.warning("âš ï¸ å»ºåº«å®Œæˆä½†åŒæ­¥å»¶é²ï¼Œè«‹æ‰‹å‹•åˆ·æ–°é é¢" if multi_lang=="ç¹é«”ä¸­æ–‡" else "âš ï¸ Sync delay, please refresh the page manually.")
                    st.toast(f"âœ… {company_name} è³‡æ–™åº«å»ºç«‹å®Œæˆï¼" if multi_lang=="ç¹é«”ä¸­æ–‡" else f"âœ… {company_name} database created!", icon="âœ…")
                    st.session_state["company_selected"] = safe_name
                    # åªè¨­ flagï¼Œæ¸…ç©ºæ“ä½œåˆ°ä¸‹æ¬¡ rerun
                    st.session_state["after_build_db"] = True
                    st.rerun()
                else:
                    st.error(f"âŒ è³‡æ–™åº«å»ºç«‹å¤±æ•—ï¼š\n{result.stderr}" if multi_lang=="ç¹é«”ä¸­æ–‡" else f"âŒ DB build failed:\n{result.stderr}")
            except Exception as e:
                st.error(f"âŒ å»ºåº«åŸ·è¡Œå¤±æ•—ï¼š{e}" if multi_lang=="ç¹é«”ä¸­æ–‡" else f"âŒ Build process failed: {e}")



companies = get_companies_list()  # ['___23bc3472', '___0b8f314d']
company_mapping = load_company_mapping()  # {'___23bc3472': 'é´»æµ·', ...}

# ç”¨ mapping å–å¾—æ‰€æœ‰é¡¯ç¤ºç”¨ä¸­æ–‡åï¼ˆè‹¥ç„¡å°±ç”¨ safe_nameï¼‰
display_names = [company_mapping.get(code, code) for code in companies]
# åæŸ¥è¡¨ï¼ˆé¡¯ç¤ºå â†’ safe_nameï¼Œç¢ºä¿é¡¯ç¤ºåå”¯ä¸€å³å¯ï¼‰
display_to_code = {display: code for display, code in zip(display_names, companies)}

print("companies =", companies)
print("company_mapping =", company_mapping)
print("display_names =", display_names)

# æ ¹æ“š session_state è¨­å®šé è¨­ index
selected_safe_name = st.session_state.get("company_selected", None)
if selected_safe_name and selected_safe_name in companies:
    # å…ˆå–å¾—ä¸­æ–‡å
    selected_display_name = company_mapping.get(selected_safe_name, selected_safe_name)
    selected_index = display_names.index(selected_display_name) + 1
else:
    selected_display_name = None  
    selected_index = 0

# é€™è£¡ sidebar ä¸‹æ‹‰ï¼Œé¡¯ç¤ºçš„åªæœ‰å…¬å¸ä¸­æ–‡å
company_display = st.sidebar.selectbox(
    T["select_company"],
    [T["select_company"]] + display_names,
    index=selected_index,
    key="company_selected_display"
)
if company_display == T["select_company"]:
    DB_FAISS_PATH = None
    company_selected = None
else:
    # é¸åˆ°çš„å…¬å¸ display name â†’ safe name
    company_selected = display_to_code[company_display]
    st.session_state["company_selected"] = company_selected
    DB_FAISS_PATH = os.path.join(VECTOR_DIR, company_selected, "db_faiss")

# å¤šèªåˆ‡æ›ï¼ˆé¡¯ç¤ºåœ¨æœ€ä¸Šé¢å·²ç¶“æœ‰ï¼Œä¸éœ€å†é‡è¤‡ï¼‰

# ====== é€²éšåŠŸèƒ½/èŠå¤©ç´€éŒ„æœå°‹/ä½¿ç”¨å»ºè­° ======
with st.sidebar.expander("ğŸ“Œ é€²éšåŠŸèƒ½" if multi_lang=="ç¹é«”ä¸­æ–‡" else "ğŸ“Œ Advanced"):
    st.markdown("ğŸ” **èŠå¤©ç´€éŒ„æœå°‹**" if multi_lang=="ç¹é«”ä¸­æ–‡" else "ğŸ” **Chat Log Search**")
    search_key = st.text_input(
        "è¼¸å…¥é—œéµå­—æœå°‹èŠå¤©ç´€éŒ„" if multi_lang=="ç¹é«”ä¸­æ–‡" else "Search keyword in chat logs", 
        key="search_history"
    )
    # æœå°‹ç¯„åœä¸‹æ‹‰é¸å–®ï¼ˆä¸­è‹±æ”¯æ´ï¼‰
    if multi_lang == "ç¹é«”ä¸­æ–‡":
        scope_options = ["ç›®å‰ä¸»é¡Œ", "æ‰€æœ‰ä¸»é¡Œ", "æ‰€æœ‰ç”¨æˆ¶"]
        scope_label = "æœå°‹ç¯„åœ"
    else:
        scope_options = ["Current topic", "All topics", "All users"]
        scope_label = "Scope"
    search_scope = st.selectbox(scope_label, scope_options, key="search_scope")

    # ä¸­è‹± mappingï¼Œæœå°‹æ™‚çµ±ä¸€ç”¨ä¸­æ–‡åšé‚è¼¯
    search_scope_mapping = {
        "ç›®å‰ä¸»é¡Œ": "ç›®å‰ä¸»é¡Œ", "Current topic": "ç›®å‰ä¸»é¡Œ",
        "æ‰€æœ‰ä¸»é¡Œ": "æ‰€æœ‰ä¸»é¡Œ", "All topics": "æ‰€æœ‰ä¸»é¡Œ",
        "æ‰€æœ‰ç”¨æˆ¶": "æ‰€æœ‰ç”¨æˆ¶", "All users": "æ‰€æœ‰ç”¨æˆ¶"
    }
    search_results = []

    if search_key:
        scope_internal = search_scope_mapping.get(search_scope, "ç›®å‰ä¸»é¡Œ")
        if scope_internal == "ç›®å‰ä¸»é¡Œ":
            history = load_chat(user_id, topic)
            for m in history:
                if search_key in m["content"]:
                    search_results.append({
                        "user": user_id,
                        "topic": topic,
                        "role": m["role"],
                        "content": m["content"]
                    })
        elif scope_internal == "æ‰€æœ‰ä¸»é¡Œ":
            topics = list_topics(user_id)
            for t in topics:
                history = load_chat(user_id, t)
                for m in history:
                    if search_key in m["content"]:
                        search_results.append({
                            "user": user_id,
                            "topic": t,
                            "role": m["role"],
                            "content": m["content"]
                        })
        elif scope_internal == "æ‰€æœ‰ç”¨æˆ¶":
            users = list_users()
            for u in users:
                topics = list_topics(u)
                for t in topics:
                    history = load_chat(u, t)
                    for m in history:
                        if search_key in m["content"]:
                            search_results.append({
                                "user": u,
                                "topic": t,
                                "role": m["role"],
                                "content": m["content"]
                            })

        st.markdown(
            f"å…±æ‰¾åˆ° <span style='color:orange;font-weight:bold'>{len(search_results)}</span> ç­†ï¼š" 
            if multi_lang=="ç¹é«”ä¸­æ–‡" 
            else f"Found <span style='color:orange;font-weight:bold'>{len(search_results)}</span> record(s):", 
            unsafe_allow_html=True
        )
        for i, m in enumerate(search_results):
            st.markdown(
                f"<b>{m['user']}/{m['topic']}</b> | {m['role']}ï¼š{m['content'][:100]}{'...' if len(m['content'])>100 else ''}",
                unsafe_allow_html=True
            )
    st.caption(
        "å¯é¸æœå°‹ã€Œç›®å‰ä¸»é¡Œã€ã€ã€Œæ‰€æœ‰ä¸»é¡Œã€ã€ã€Œæ‰€æœ‰ç”¨æˆ¶ã€" if multi_lang=="ç¹é«”ä¸­æ–‡" 
        else "You can search in current topic / all topics / all users"
    )

st.sidebar.info(
    """  
ğŸ’¡ ä½¿ç”¨å»ºè­°ï¼š
- å…ˆä¸Šå‚³å…¬å¸è²¡å ± PDFï¼Œè‡ªå‹•å»ºç«‹è³‡æ–™åº«
- å¯åˆ‡æ›å…¬å¸/èªè¨€ï¼Œè‡ªç”±æŸ¥è©¢
- å¯åˆ†ä¸»é¡Œç®¡ç†å°è©±èˆ‡æ­·å²æŸ¥è©¢
- æå•å¾Œå¯ç”¨ /åˆ†æ é€²è¡Œæƒ…ç·’é æ¸¬
- å›è¦†å…§å®¹æ›´è²¼è¿‘ AI å£å»ï¼Œè‡ªç„¶ç°¡æ˜
""" if multi_lang=="ç¹é«”ä¸­æ–‡" else
    """  
ğŸ’¡ Suggestions:
- Upload company financial PDF first to build the database
- Switch company/language freely for queries
- Manage topics and chat history
- Use /analyze for sentiment analysis
- Answers are now more conversational and AI-like
""")

tab1, tab2, tab3 = st.tabs([T["tab1"], T["tab2"], T["tab3"]])

# <<<< åˆå§‹åŒ– session_state["messages"]
if "messages" not in st.session_state:
    try:
        st.session_state["messages"] = load_chat(user_id, topic)
    except Exception:
        st.session_state["messages"] = []

# ========== åˆ†é 1ï¼šAIå•ç­” ==========

# åˆå§‹åŒ–åˆ†é 1çš„èŠå¤©ç´€éŒ„
if "messages_tab1" not in st.session_state:
    try:
        st.session_state["messages_tab1"] = load_chat(user_id, topic)
    except Exception:
        st.session_state["messages_tab1"] = []

with tab1:
    st.title(T["chat_title"])
    st.markdown(
        """è«‹è¼¸å…¥æ‚¨çš„å•é¡Œï¼ˆä¸­è‹±æ–‡çš†å¯ï¼‰ï¼Œä¾‹å¦‚ï¼š\n- å°ç©é›» 2024 å¹´ç¬¬ä¸€å­£çš„ç‡Ÿæ¥­æ”¶å…¥æ˜¯å¤šå°‘ï¼Ÿ\n- What is TSMC's Q1 2024 revenue?\n- /åˆ†æ é æœŸæœªä¾†æŠ˜èˆŠè²»ç”¨å°‡ä¸Šå‡"""
        if multi_lang=="ç¹é«”ä¸­æ–‡" else
        """Ask your question (either language), e.g.:\n- What is TSMC's Q1 2024 revenue?\n- å°ç©é›» 2024 å¹´ç¬¬ä¸€å­£çš„ç‡Ÿæ¥­æ”¶å…¥æ˜¯å¤šå°‘ï¼Ÿ\n- /analyze Depreciation expense is expected to rise"""
    )

    if st.button(T["clear_chat"], key="clear_chat"):
        st.session_state["messages_tab1"] = []
        save_chat(st.session_state["messages_tab1"], user_id, topic)
        st.rerun()

    for chat in st.session_state["messages_tab1"]:
        with st.chat_message(chat["role"]):
            st.markdown(chat["content"], unsafe_allow_html=True)

user_input = st.chat_input(T["chat_input"], key="ai_chat")
if user_input:
    st.session_state["messages_tab1"].append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)
    with st.spinner("AI æ­£åœ¨æŸ¥è©¢è³‡æ–™..." if multi_lang == "ç¹é«”ä¸­æ–‡" else "AI is searching..."):
        try:
            if selected_model == "Qwen1.8":
                answer = ""
                amount = "ï¼ˆæŸ¥ç„¡ï¼‰" if multi_lang == "ç¹é«”ä¸­æ–‡" else "(No data)"
                growth = "ï¼ˆæŸ¥ç„¡ï¼‰" if multi_lang == "ç¹é«”ä¸­æ–‡" else "(No data)"
                source_snippets = []
                news_list = []
                used_pdf = False
                if DB_FAISS_PATH and os.path.exists(DB_FAISS_PATH):
                    qa = get_qa_bot(DB_FAISS_PATH, multi_lang)
                    if qa:
                        result = qa.invoke({"query": user_input})
                        if isinstance(result, dict):
                            answer = result.get("result") or result.get("output_text") or ""
                            source_documents = result.get("source_documents", [])
                        else:
                            answer = result if isinstance(result, str) else str(result)
                            source_documents = []
                        amount = extract_amount_by_type(answer, user_input)
                        if not amount and source_documents:
                            for doc in source_documents:
                                amount = extract_amount_by_type(doc.page_content, user_input)
                                if amount:
                                    break
                        def extract_growth(text):
                            match = re.search(r"(å¹´å¢ç‡|å¹´æˆé•·ç‡)[\s:ï¼š]*([\-0-9\.]+%)", text)
                            return match.group(2) if match else None
                        growth = extract_growth(answer)
                        if not growth and source_documents:
                            for doc in source_documents:
                                growth = extract_growth(doc.page_content)
                                if growth:
                                    break
                        if amount:
                            used_pdf = True
                            source_snippets = []
                            for doc in source_documents[:3]:
                                snippet = doc.page_content.strip()
                                if len(snippet) > 80:
                                    snippet = snippet[:80] + "..."
                                source_snippets.append(snippet)

                # æ²’æŸ¥åˆ° PDF é‡‘é¡ â†’ è‡ªå‹•è£œç¶²è·¯
                if not used_pdf:
                    st.info("â—ï¸æœªåœ¨è²¡å ±PDFä¸­æ“·å–åˆ°é—œéµé‡‘é¡ï¼Œå·²è‡ªå‹•è£œä¸Šç¶²è·¯è³‡æ–™" if multi_lang == "ç¹é«”ä¸­æ–‡" else "â—ï¸Not found in PDF, using web data")
                    news_result = web_search(user_input)
                    amount, news_list, source_snippets = parse_web_search_result(news_result, user_input)
                    answer = "ï¼ˆä¾†è‡ªç¶²è·¯ï¼‰" if multi_lang == "ç¹é«”ä¸­æ–‡" else "(From web)"
                    growth = "ï¼ˆæŸ¥ç„¡ï¼‰" if multi_lang == "ç¹é«”ä¸­æ–‡" else "(No data)"

                def extract_company_from_question(question):
                    known_companies = ["å°ç©é›»", "é´»æµ·", "è¯ç™¼ç§‘", "è¯é›»", "å¤§ç«‹å…‰", "æ—¥æœˆå…‰"]
                    for c in known_companies:
                        if c in question:
                            return c
                    return company_selected or ("ï¼ˆè‡ªå‹•åˆ¤æ–·å…¬å¸ï¼‰" if multi_lang == "ç¹é«”ä¸­æ–‡" else "(Auto company detect)")
                company_name = extract_company_from_question(user_input)

                reply = build_ai_reply(
                    company_mapping.get(company_name, company_name),  # é¡¯ç¤ºç”¨ä¸­æ–‡å
                    user_input,
                    answer,
                    amount or ("ï¼ˆæŸ¥ç„¡ï¼‰" if multi_lang == "ç¹é«”ä¸­æ–‡" else "(No data)"),
                    growth or ("ï¼ˆæŸ¥ç„¡ï¼‰" if multi_lang == "ç¹é«”ä¸­æ–‡" else "(No data)"),
                    news_list,
                    source_snippets,
                    T
                )

            elif selected_model == "OpenAI GPT-4o":
                # ==== æ”¹ï¼šæ°¸é å„ªå…ˆç¶²è·¯æŠ“æ•¸å­—ï¼ŒæŠ“åˆ°å°±ç›´æ¥ç”¨ ====
                news_result = web_search(user_input)
                amount, news_list, source_snippets = parse_web_search_result(news_result, user_input)

                if amount and amount not in ["ï¼ˆæŸ¥ç„¡ï¼‰", "(No data)"]:
                    # å¦‚æœæœ‰æ•¸å­— â†’ ç›´æ¥é¡¯ç¤ºç¶²è·¯æ•¸å­—èˆ‡ä¾†æºï¼ˆå¯é¸GPTè¼”åŠ©æ‘˜è¦ï¼‰
                    gpt_summary = ask_openai(
                        f"æ ¹æ“šä»¥ä¸‹æœ€æ–°å…¬é–‹è³‡è¨Šï¼Œè«‹æ¢åˆ—æœ¬å­£è²¡å ±é‡é»ã€è¶¨å‹¢èˆ‡å°ˆæ¥­è§€é»ï¼š\n\n{news_result}",
                        lang=multi_lang,
                        history=[]
                    )
                    reply = f"""ğŸŒ **ç¶²è·¯æœ€æ–°æ•¸å­—ï¼š**  
- **{amount}**

{news_result}

---

**AI åˆ†æè£œå……ï¼š**
{gpt_summary}
"""
                else:
                    # æ²’æŠ“åˆ°ç¶²è·¯æ•¸å­—æ‰ç”¨GPT
                    history_msgs = []
                    for m in st.session_state["messages_tab1"]:
                        if m["role"] in ("user", "assistant"):
                            content = m["content"]
                            if len(content) > 1500:
                                content = content[:1500] + "..."
                            history_msgs.append({"role": m["role"], "content": content})
                    answer = ask_openai(user_input, lang=multi_lang, history=history_msgs)
                    reply = f"ğŸŒ **OpenAI GPT å›è¦†ï¼š**\n\n{answer}" if multi_lang == "ç¹é«”ä¸­æ–‡" else f"ğŸŒ **OpenAI GPT Answer:**\n\n{answer}"

            else:
                reply = "è«‹é¸æ“‡æœ‰æ•ˆçš„æ¨¡å‹ã€‚" if multi_lang == "ç¹é«”ä¸­æ–‡" else "Please select a valid model."
        except Exception as e:
            reply = f"âŒ å•ç­”éç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}" if multi_lang == "ç¹é«”ä¸­æ–‡" else f"âŒ Error occurred: {e}"
    st.session_state["messages_tab1"].append({"role": "assistant", "content": reply})
    with st.chat_message("assistant"):
        st.markdown(reply, unsafe_allow_html=True)
    save_chat(st.session_state["messages_tab1"], user_id, topic)
    st.toast("å·²å®Œæˆå›ç­”" if multi_lang == "ç¹é«”ä¸­æ–‡" else "Answer complete", icon="ğŸ¤–")


# ========== åˆ†é 2ï¼šè²¡å ±æ‘˜è¦ ==========
with tab2:
    st.title(T["tab2_title"])
    st.markdown(T["tab2_markdown"])

    input_text = st.text_area(
        T["tab2_input_placeholder"], ""
    )

    if st.button(T["tab2_analyze_btn2"]):
        if not input_text.strip():
            st.warning(T["tab2_enter_content"])
        else:
            with st.spinner(T["tab2_spinner_analyze"]):
                # æ¢åˆ—ä¸‰å€‹é‡é»
                summary_prompt = (
                    "è«‹é–±è®€ä¸‹åˆ—å…§å®¹ï¼Œæ¢åˆ—ä¸‰å€‹ç¶“ç‡Ÿé‡é»ï¼ˆæ¯é»15å­—å…§ï¼Œä¸è¦æŠ„åŸæ–‡ï¼‰ï¼š\n\n"
                    if multi_lang == "ç¹é«”ä¸­æ–‡"
                    else "Read the following and list three business highlights (no more than 15 words each, do not copy the original):\n\n"
                ) + input_text
                summary = ask_openai(summary_prompt, lang=multi_lang)

                # åˆ¤æ–·æƒ…ç·’
                sentiment_prompt = (
                    "è«‹é–±è®€ä¸‹åˆ—å…§å®¹ï¼Œåˆ¤æ–·ç¶“ç‡Ÿæƒ…ç·’ä¸¦åªå›è¦†ä¸€å€‹è©ï¼ˆæ¨‚è§€/ä¸­æ€§/ä¿å®ˆï¼‰ï¼š\n\n"
                    if multi_lang == "ç¹é«”ä¸­æ–‡"
                    else "Read the following, judge the management sentiment, and only reply with one word (Optimistic/Neutral/Conservative):\n\n"
                ) + input_text
                sentiment = ask_openai(sentiment_prompt, lang=multi_lang)

                # é¡¯ç¤º
                st.markdown(f"#### {T['tab2_key_summary']}")
                st.markdown(summary)
                st.markdown(
                    f"#### {T['tab2_sentiment']}<span style='color:orange;font-weight:bold'>{sentiment}</span>",
                    unsafe_allow_html=True
                )

# ========== åˆ†é 3ï¼šè²¡å ±åœ–è¡¨ ==========
with tab3:
    st.title(T["tab3"])
    st.markdown(T["tab3_title"])
    indicator_options = ["ç‡Ÿæ”¶", "æ·¨åˆ©", "EPS", "æ¯›åˆ©ç‡"] if multi_lang == "ç¹é«”ä¸­æ–‡" else ["Revenue", "Net Income", "EPS", "Gross Margin"]

    # ...é¸å…¬å¸ç•¥...

    st.subheader(T["tab3_multi_title"])
    selected_companies_display = st.multiselect(
        T["tab3_multi_company"],
        display_names,
        default=[display_names[0]] if display_names else [],
        key="tab3_multi_company"
    )
    selected_companies = [display_to_code[d] for d in selected_companies_display]
    compare_indicator = st.selectbox(
        T["tab3_multi_indicator"],
        indicator_options,
        index=0,
        key="compare_indicator"
    )
    year_range = st.slider(
        T["tab3_year"], 
        min_value=2015, 
        max_value=datetime.now().year, 
        value=(2020, datetime.now().year), 
        key="tab3_year_multi"
    )

    # --- æ¯”è¼ƒ/åˆªé™¤å…©é¡†æŒ‰éˆ•åŒä¸€è¡Œ ---
    btn_col1, btn_col2 = st.columns([1, 1])
    with btn_col1:
        compare_btn_clicked = st.button(T["tab3_multi_btn"], key="compare_btn", use_container_width=True)
    with btn_col2:
        delete_btn_clicked = st.button("ğŸ—‘ï¸", key="delete_chart_btn", use_container_width=True, help="åˆªé™¤åœ–è¡¨")

    # å­˜æ”¾åœ–è¡¨è³‡æ–™
    if "multi_chart_df" not in st.session_state:
        st.session_state["multi_chart_df"] = None

    # æŸ¥è©¢èˆ‡åˆªé™¤å‹•ä½œ
    if compare_btn_clicked:
        if not selected_companies:
            st.warning(T["tab3_multi_no_company"])
            st.session_state["multi_chart_df"] = None
        else:
            with st.spinner(T["tab3_multi_spinner"]):
                selected_display_names = [company_mapping.get(code, code) for code in selected_companies]
                years = list(range(year_range[0], year_range[1]+1))
                df = get_company_year_data(selected_display_names, compare_indicator, years)
                if not df.empty and "%" not in compare_indicator:
                    df[compare_indicator] = df[compare_indicator] / 1e8
                st.session_state["multi_chart_df"] = df

    if delete_btn_clicked:
        st.session_state["multi_chart_df"] = None

    df = st.session_state.get("multi_chart_df", None)
    # åœ–è¡¨èˆ‡å¯¬é«˜æ»‘æ¢åŒä¸€è¡Œï¼ˆåªæœ‰æŸ¥è©¢éæ‰å‡ºç¾ï¼‰
    if df is not None and not df.empty:
        chart_col, slider_col = st.columns([5, 1])
        # æ»‘æ¢åªè¦æœ‰åœ–å°±ä¸€ç›´åœ¨æ—é‚Šã€å³æ™‚æ›´æ–°
        with slider_col:
            chart_width = st.slider("å¯¬åº¦", min_value=2.0, max_value=8.0, value=3.2, step=0.1, key="chart_width_multi")
            chart_height = st.slider("é«˜åº¦", min_value=1.0, max_value=5.0, value=2.0, step=0.1, key="chart_height_multi")
        with chart_col:
            fig, ax = plt.subplots(figsize=(chart_width, chart_height))
            for company in df["å…¬å¸"].unique():
                df_c = df[df["å…¬å¸"] == company].sort_values("å¹´åº¦")
                label = f"{company} ({df_c['ä¾†æº'].iloc[0]})"
                ax.plot(df_c["å¹´åº¦"], df_c[compare_indicator], marker="o", label=label)
            if "%" in compare_indicator or compare_indicator in ["æ¯›åˆ©ç‡", "Gross Margin"]:
                ax.set_ylabel(compare_indicator + ("ï¼ˆ%ï¼‰" if multi_lang == "ç¹é«”ä¸­æ–‡" else " (%)"))
            else:
                ax.set_ylabel(compare_indicator + ("ï¼ˆå„„å…ƒï¼‰" if multi_lang == "ç¹é«”ä¸­æ–‡" else " (100M)"))
            ax.set_xlabel("å¹´åº¦" if multi_lang == "ç¹é«”ä¸­æ–‡" else "Year")
            ax.set_title(T["tab3_chart_title"].format(indicator=compare_indicator), fontsize=14)
            # ==== legend æ”¾åœ–å¤–å³å´ã€å­—é«”ç¸®å° ====
            ax.legend(
                fontsize=8,
                bbox_to_anchor=(1.01, 0.5),
                loc='center left',
                borderaxespad=0.
            )
            ax.grid(True)
            st.pyplot(fig, use_container_width=False)
            st.write(df)
    elif df is not None and df.empty:
        st.warning(T["tab3_multi_no_data"])

